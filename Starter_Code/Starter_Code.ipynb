{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE  AFFILIATION CLASSIFICATION    USE_CASE ORGANIZATION  \\\n",
       "0              T10  Independent          C1000  ProductDev  Association   \n",
       "\n",
       "   STATUS INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0       1          0                      N     5000              1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df.drop(['EIN', 'NAME'],  axis=1, inplace=True)\n",
    "# application_df = application_df.loc[:, ~application_df.columns.str.contains('^Unnamed')]\n",
    "application_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            17\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION              71\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "application_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T25        3\n",
       "T14        3\n",
       "T29        2\n",
       "T15        2\n",
       "T17        1\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "application_type_counts = application_df['APPLICATION_TYPE'].value_counts()\n",
    "application_type_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "Other     2266\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "application_types_to_replace = list(application_type_counts[application_type_counts < 750].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "application_df['APPLICATION_TYPE'].value_counts()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "         ...  \n",
       "C4120        1\n",
       "C8210        1\n",
       "C2561        1\n",
       "C4500        1\n",
       "C2150        1\n",
       "Name: CLASSIFICATION, Length: 71, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "classification_val_counts = application_df['CLASSIFICATION'].value_counts()\n",
    "classification_val_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "C2800       95\n",
       "C7100       75\n",
       "C1300       58\n",
       "C1280       50\n",
       "C1230       36\n",
       "C1400       34\n",
       "C7200       32\n",
       "C2300       32\n",
       "C1240       30\n",
       "C8000       20\n",
       "C7120       18\n",
       "C1500       16\n",
       "C1800       15\n",
       "C6000       15\n",
       "C1250       14\n",
       "C8200       11\n",
       "C1238       10\n",
       "C1278       10\n",
       "C1235        9\n",
       "C1237        9\n",
       "C7210        7\n",
       "C2400        6\n",
       "C1720        6\n",
       "C4100        6\n",
       "C1257        5\n",
       "C1600        5\n",
       "C1260        3\n",
       "C2710        3\n",
       "C0           3\n",
       "C3200        2\n",
       "C1234        2\n",
       "C1246        2\n",
       "C1267        2\n",
       "C1256        2\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
    "greater_than_one = classification_val_counts[classification_val_counts>1]\n",
    "greater_than_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Other     1484\n",
       "C7000      777\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "classifications_to_replace = list (classification_val_counts[classification_val_counts<750].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "application_df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0       1     5000              1                     1.0   \n",
       "1       1   108590              1                     0.0   \n",
       "2       1     5000              0                     0.0   \n",
       "3       1     6692              1                     0.0   \n",
       "4       1   142590              1                     0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  \\\n",
       "0                   0.0                  0.0                  0.0   \n",
       "1                   0.0                  1.0                  0.0   \n",
       "2                   0.0                  0.0                  0.0   \n",
       "3                   0.0                  1.0                  0.0   \n",
       "4                   0.0                  1.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  AFFILIATION_CompanySponsored  \\\n",
       "0                  0.0                  0.0                           0.0   \n",
       "1                  0.0                  0.0                           0.0   \n",
       "2                  1.0                  0.0                           1.0   \n",
       "3                  0.0                  0.0                           1.0   \n",
       "4                  0.0                  0.0                           0.0   \n",
       "\n",
       "   ...  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0  ...                0.0                     0.0                       0.0   \n",
       "1  ...                1.0                     0.0                       0.0   \n",
       "2  ...                0.0                     0.0                       0.0   \n",
       "3  ...                0.0                     1.0                       0.0   \n",
       "4  ...                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "application_df = pd.get_dummies(application_df,dtype=float)\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\AppData\\Local\\Temp\\ipykernel_10352\\1048604523.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  X = application_df.drop(['IS_SUCCESSFUL'],1).values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.000000e+00, 2.631396e+06, 0.000000e+00, ..., 0.000000e+00,\n",
       "        1.000000e+00, 0.000000e+00],\n",
       "       [1.000000e+00, 5.000000e+03, 0.000000e+00, ..., 0.000000e+00,\n",
       "        1.000000e+00, 0.000000e+00],\n",
       "       [1.000000e+00, 5.000000e+03, 0.000000e+00, ..., 0.000000e+00,\n",
       "        1.000000e+00, 0.000000e+00],\n",
       "       ...,\n",
       "       [1.000000e+00, 1.443006e+06, 0.000000e+00, ..., 0.000000e+00,\n",
       "        1.000000e+00, 0.000000e+00],\n",
       "       [1.000000e+00, 5.000000e+03, 0.000000e+00, ..., 0.000000e+00,\n",
       "        1.000000e+00, 0.000000e+00],\n",
       "       [1.000000e+00, 5.000000e+03, 0.000000e+00, ..., 0.000000e+00,\n",
       "        1.000000e+00, 0.000000e+00]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = application_df['IS_SUCCESSFUL'].values\n",
    "X = application_df.drop(['IS_SUCCESSFUL'],1).values\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=50)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                504       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                312       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 841 (3.29 KB)\n",
      "Trainable params: 841 (3.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "features = len( X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 12\n",
    "hidden_nodes_layer2 = 24\n",
    "# hidden_nodes_layer3 = 36 # Using this layer results worsenLoss: 0.5824776291847229, Accuracy: 0.7370262145996094\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=features, activation='relu'))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, input_dim=features, activation='relu'))\n",
    "\n",
    "# third hidden\n",
    "# nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, input_dim=features, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/780\n",
      "684/684 [==============================] - 2s 2ms/step - loss: 0.6081 - accuracy: 0.6945 - val_loss: 0.5608 - val_accuracy: 0.7339\n",
      "Epoch 2/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5725 - accuracy: 0.7218 - val_loss: 0.5530 - val_accuracy: 0.7359\n",
      "Epoch 3/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5672 - accuracy: 0.7231 - val_loss: 0.5587 - val_accuracy: 0.7357\n",
      "Epoch 4/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5651 - accuracy: 0.7235 - val_loss: 0.5572 - val_accuracy: 0.7346\n",
      "Epoch 5/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5630 - accuracy: 0.7240 - val_loss: 0.5514 - val_accuracy: 0.7396\n",
      "Epoch 6/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5617 - accuracy: 0.7258 - val_loss: 0.5465 - val_accuracy: 0.7380\n",
      "Epoch 7/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5602 - accuracy: 0.7256 - val_loss: 0.5464 - val_accuracy: 0.7375\n",
      "Epoch 8/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5593 - accuracy: 0.7257 - val_loss: 0.5460 - val_accuracy: 0.7396\n",
      "Epoch 9/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5583 - accuracy: 0.7268 - val_loss: 0.5475 - val_accuracy: 0.7391\n",
      "Epoch 10/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5578 - accuracy: 0.7265 - val_loss: 0.5479 - val_accuracy: 0.7383\n",
      "Epoch 11/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5577 - accuracy: 0.7266 - val_loss: 0.5458 - val_accuracy: 0.7385\n",
      "Epoch 12/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5568 - accuracy: 0.7277 - val_loss: 0.5494 - val_accuracy: 0.7385\n",
      "Epoch 13/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5567 - accuracy: 0.7271 - val_loss: 0.5483 - val_accuracy: 0.7396\n",
      "Epoch 14/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5563 - accuracy: 0.7271 - val_loss: 0.5473 - val_accuracy: 0.7388\n",
      "Epoch 15/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5558 - accuracy: 0.7276 - val_loss: 0.5480 - val_accuracy: 0.7365\n",
      "Epoch 16/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5552 - accuracy: 0.7282 - val_loss: 0.5480 - val_accuracy: 0.7375\n",
      "Epoch 17/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5551 - accuracy: 0.7276 - val_loss: 0.5462 - val_accuracy: 0.7391\n",
      "Epoch 18/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5543 - accuracy: 0.7273 - val_loss: 0.5481 - val_accuracy: 0.7385\n",
      "Epoch 19/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5548 - accuracy: 0.7286 - val_loss: 0.5483 - val_accuracy: 0.7378\n",
      "Epoch 20/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5543 - accuracy: 0.7282 - val_loss: 0.5468 - val_accuracy: 0.7372\n",
      "Epoch 21/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5534 - accuracy: 0.7282 - val_loss: 0.5506 - val_accuracy: 0.7385\n",
      "Epoch 22/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5533 - accuracy: 0.7292 - val_loss: 0.5470 - val_accuracy: 0.7380\n",
      "Epoch 23/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5536 - accuracy: 0.7280 - val_loss: 0.5460 - val_accuracy: 0.7375\n",
      "Epoch 24/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5532 - accuracy: 0.7284 - val_loss: 0.5486 - val_accuracy: 0.7388\n",
      "Epoch 25/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5529 - accuracy: 0.7286 - val_loss: 0.5489 - val_accuracy: 0.7375\n",
      "Epoch 26/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5528 - accuracy: 0.7282 - val_loss: 0.5490 - val_accuracy: 0.7378\n",
      "Epoch 27/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5523 - accuracy: 0.7289 - val_loss: 0.5491 - val_accuracy: 0.7393\n",
      "Epoch 28/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5528 - accuracy: 0.7286 - val_loss: 0.5474 - val_accuracy: 0.7383\n",
      "Epoch 29/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5523 - accuracy: 0.7292 - val_loss: 0.5458 - val_accuracy: 0.7383\n",
      "Epoch 30/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5525 - accuracy: 0.7280 - val_loss: 0.5463 - val_accuracy: 0.7362\n",
      "Epoch 31/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5522 - accuracy: 0.7292 - val_loss: 0.5456 - val_accuracy: 0.7393\n",
      "Epoch 32/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5521 - accuracy: 0.7301 - val_loss: 0.5474 - val_accuracy: 0.7391\n",
      "Epoch 33/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7297 - val_loss: 0.5497 - val_accuracy: 0.7357\n",
      "Epoch 34/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5518 - accuracy: 0.7286 - val_loss: 0.5499 - val_accuracy: 0.7359\n",
      "Epoch 35/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5518 - accuracy: 0.7304 - val_loss: 0.5465 - val_accuracy: 0.7383\n",
      "Epoch 36/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5517 - accuracy: 0.7296 - val_loss: 0.5493 - val_accuracy: 0.7375\n",
      "Epoch 37/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5514 - accuracy: 0.7294 - val_loss: 0.5481 - val_accuracy: 0.7391\n",
      "Epoch 38/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5515 - accuracy: 0.7307 - val_loss: 0.5470 - val_accuracy: 0.7388\n",
      "Epoch 39/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5511 - accuracy: 0.7303 - val_loss: 0.5490 - val_accuracy: 0.7391\n",
      "Epoch 40/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5512 - accuracy: 0.7304 - val_loss: 0.5473 - val_accuracy: 0.7385\n",
      "Epoch 41/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5512 - accuracy: 0.7297 - val_loss: 0.5494 - val_accuracy: 0.7385\n",
      "Epoch 42/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5510 - accuracy: 0.7296 - val_loss: 0.5495 - val_accuracy: 0.7362\n",
      "Epoch 43/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5505 - accuracy: 0.7312 - val_loss: 0.5492 - val_accuracy: 0.7372\n",
      "Epoch 44/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5511 - accuracy: 0.7294 - val_loss: 0.5492 - val_accuracy: 0.7349\n",
      "Epoch 45/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5510 - accuracy: 0.7294 - val_loss: 0.5485 - val_accuracy: 0.7388\n",
      "Epoch 46/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5509 - accuracy: 0.7304 - val_loss: 0.5490 - val_accuracy: 0.7354\n",
      "Epoch 47/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5510 - accuracy: 0.7304 - val_loss: 0.5492 - val_accuracy: 0.7370\n",
      "Epoch 48/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5505 - accuracy: 0.7300 - val_loss: 0.5504 - val_accuracy: 0.7378\n",
      "Epoch 49/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5505 - accuracy: 0.7302 - val_loss: 0.5547 - val_accuracy: 0.7367\n",
      "Epoch 50/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5505 - accuracy: 0.7303 - val_loss: 0.5491 - val_accuracy: 0.7372\n",
      "Epoch 51/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5506 - accuracy: 0.7297 - val_loss: 0.5508 - val_accuracy: 0.7385\n",
      "Epoch 52/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5501 - accuracy: 0.7302 - val_loss: 0.5505 - val_accuracy: 0.7388\n",
      "Epoch 53/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5503 - accuracy: 0.7305 - val_loss: 0.5493 - val_accuracy: 0.7378\n",
      "Epoch 54/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5497 - accuracy: 0.7311 - val_loss: 0.5518 - val_accuracy: 0.7380\n",
      "Epoch 55/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5504 - accuracy: 0.7312 - val_loss: 0.5503 - val_accuracy: 0.7352\n",
      "Epoch 56/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5500 - accuracy: 0.7308 - val_loss: 0.5497 - val_accuracy: 0.7383\n",
      "Epoch 57/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5496 - accuracy: 0.7306 - val_loss: 0.5507 - val_accuracy: 0.7383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5494 - accuracy: 0.7310 - val_loss: 0.5502 - val_accuracy: 0.7362\n",
      "Epoch 59/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5496 - accuracy: 0.7304 - val_loss: 0.5544 - val_accuracy: 0.7378\n",
      "Epoch 60/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5499 - accuracy: 0.7304 - val_loss: 0.5497 - val_accuracy: 0.7388\n",
      "Epoch 61/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5500 - accuracy: 0.7312 - val_loss: 0.5489 - val_accuracy: 0.7388\n",
      "Epoch 62/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5494 - accuracy: 0.7311 - val_loss: 0.5501 - val_accuracy: 0.7380\n",
      "Epoch 63/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5495 - accuracy: 0.7311 - val_loss: 0.5513 - val_accuracy: 0.7375\n",
      "Epoch 64/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5494 - accuracy: 0.7317 - val_loss: 0.5490 - val_accuracy: 0.7378\n",
      "Epoch 65/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5494 - accuracy: 0.7308 - val_loss: 0.5521 - val_accuracy: 0.7367\n",
      "Epoch 66/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5494 - accuracy: 0.7311 - val_loss: 0.5510 - val_accuracy: 0.7383\n",
      "Epoch 67/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5486 - accuracy: 0.7312 - val_loss: 0.5558 - val_accuracy: 0.7344\n",
      "Epoch 68/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5492 - accuracy: 0.7311 - val_loss: 0.5520 - val_accuracy: 0.7367\n",
      "Epoch 69/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5495 - accuracy: 0.7302 - val_loss: 0.5522 - val_accuracy: 0.7380\n",
      "Epoch 70/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5490 - accuracy: 0.7309 - val_loss: 0.5521 - val_accuracy: 0.7388\n",
      "Epoch 71/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5489 - accuracy: 0.7314 - val_loss: 0.5539 - val_accuracy: 0.7372\n",
      "Epoch 72/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5487 - accuracy: 0.7325 - val_loss: 0.5511 - val_accuracy: 0.7370\n",
      "Epoch 73/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5487 - accuracy: 0.7309 - val_loss: 0.5520 - val_accuracy: 0.7372\n",
      "Epoch 74/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5486 - accuracy: 0.7314 - val_loss: 0.5563 - val_accuracy: 0.7354\n",
      "Epoch 75/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5491 - accuracy: 0.7313 - val_loss: 0.5551 - val_accuracy: 0.7359\n",
      "Epoch 76/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5487 - accuracy: 0.7318 - val_loss: 0.5508 - val_accuracy: 0.7370\n",
      "Epoch 77/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5482 - accuracy: 0.7319 - val_loss: 0.5516 - val_accuracy: 0.7370\n",
      "Epoch 78/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5486 - accuracy: 0.7316 - val_loss: 0.5531 - val_accuracy: 0.7378\n",
      "Epoch 79/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5483 - accuracy: 0.7317 - val_loss: 0.5486 - val_accuracy: 0.7398\n",
      "Epoch 80/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5484 - accuracy: 0.7324 - val_loss: 0.5550 - val_accuracy: 0.7359\n",
      "Epoch 81/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5485 - accuracy: 0.7316 - val_loss: 0.5522 - val_accuracy: 0.7378\n",
      "Epoch 82/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5484 - accuracy: 0.7316 - val_loss: 0.5519 - val_accuracy: 0.7380\n",
      "Epoch 83/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5482 - accuracy: 0.7324 - val_loss: 0.5519 - val_accuracy: 0.7391\n",
      "Epoch 84/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5484 - accuracy: 0.7318 - val_loss: 0.5530 - val_accuracy: 0.7365\n",
      "Epoch 85/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5481 - accuracy: 0.7316 - val_loss: 0.5507 - val_accuracy: 0.7393\n",
      "Epoch 86/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5482 - accuracy: 0.7322 - val_loss: 0.5520 - val_accuracy: 0.7385\n",
      "Epoch 87/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5482 - accuracy: 0.7315 - val_loss: 0.5546 - val_accuracy: 0.7380\n",
      "Epoch 88/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5483 - accuracy: 0.7317 - val_loss: 0.5521 - val_accuracy: 0.7385\n",
      "Epoch 89/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5481 - accuracy: 0.7317 - val_loss: 0.5524 - val_accuracy: 0.7385\n",
      "Epoch 90/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5481 - accuracy: 0.7314 - val_loss: 0.5520 - val_accuracy: 0.7380\n",
      "Epoch 91/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5481 - accuracy: 0.7321 - val_loss: 0.5525 - val_accuracy: 0.7378\n",
      "Epoch 92/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5480 - accuracy: 0.7330 - val_loss: 0.5512 - val_accuracy: 0.7378\n",
      "Epoch 93/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5480 - accuracy: 0.7324 - val_loss: 0.5510 - val_accuracy: 0.7401\n",
      "Epoch 94/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5477 - accuracy: 0.7326 - val_loss: 0.5513 - val_accuracy: 0.7383\n",
      "Epoch 95/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5477 - accuracy: 0.7321 - val_loss: 0.5526 - val_accuracy: 0.7398\n",
      "Epoch 96/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5477 - accuracy: 0.7316 - val_loss: 0.5494 - val_accuracy: 0.7396\n",
      "Epoch 97/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5478 - accuracy: 0.7327 - val_loss: 0.5537 - val_accuracy: 0.7388\n",
      "Epoch 98/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5476 - accuracy: 0.7321 - val_loss: 0.5536 - val_accuracy: 0.7393\n",
      "Epoch 99/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5479 - accuracy: 0.7319 - val_loss: 0.5562 - val_accuracy: 0.7393\n",
      "Epoch 100/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5474 - accuracy: 0.7324 - val_loss: 0.5518 - val_accuracy: 0.7391\n",
      "Epoch 101/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5474 - accuracy: 0.7331 - val_loss: 0.5537 - val_accuracy: 0.7396\n",
      "Epoch 102/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5476 - accuracy: 0.7324 - val_loss: 0.5547 - val_accuracy: 0.7354\n",
      "Epoch 103/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5473 - accuracy: 0.7320 - val_loss: 0.5519 - val_accuracy: 0.7388\n",
      "Epoch 104/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5477 - accuracy: 0.7320 - val_loss: 0.5523 - val_accuracy: 0.7378\n",
      "Epoch 105/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5475 - accuracy: 0.7325 - val_loss: 0.5508 - val_accuracy: 0.7398\n",
      "Epoch 106/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5471 - accuracy: 0.7316 - val_loss: 0.5508 - val_accuracy: 0.7383\n",
      "Epoch 107/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5475 - accuracy: 0.7313 - val_loss: 0.5510 - val_accuracy: 0.7375\n",
      "Epoch 108/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5474 - accuracy: 0.7327 - val_loss: 0.5534 - val_accuracy: 0.7396\n",
      "Epoch 109/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5470 - accuracy: 0.7326 - val_loss: 0.5512 - val_accuracy: 0.7406\n",
      "Epoch 110/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5473 - accuracy: 0.7324 - val_loss: 0.5538 - val_accuracy: 0.7383\n",
      "Epoch 111/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5472 - accuracy: 0.7325 - val_loss: 0.5524 - val_accuracy: 0.7375\n",
      "Epoch 112/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5472 - accuracy: 0.7330 - val_loss: 0.5539 - val_accuracy: 0.7383\n",
      "Epoch 113/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5473 - accuracy: 0.7320 - val_loss: 0.5520 - val_accuracy: 0.7385\n",
      "Epoch 114/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5469 - accuracy: 0.7333 - val_loss: 0.5539 - val_accuracy: 0.7398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5470 - accuracy: 0.7321 - val_loss: 0.5517 - val_accuracy: 0.7388\n",
      "Epoch 116/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5471 - accuracy: 0.7324 - val_loss: 0.5535 - val_accuracy: 0.7391\n",
      "Epoch 117/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5469 - accuracy: 0.7333 - val_loss: 0.5533 - val_accuracy: 0.7372\n",
      "Epoch 118/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5472 - accuracy: 0.7312 - val_loss: 0.5528 - val_accuracy: 0.7401\n",
      "Epoch 119/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5469 - accuracy: 0.7327 - val_loss: 0.5516 - val_accuracy: 0.7401\n",
      "Epoch 120/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5466 - accuracy: 0.7328 - val_loss: 0.5521 - val_accuracy: 0.7380\n",
      "Epoch 121/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5467 - accuracy: 0.7326 - val_loss: 0.5553 - val_accuracy: 0.7352\n",
      "Epoch 122/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5470 - accuracy: 0.7318 - val_loss: 0.5534 - val_accuracy: 0.7393\n",
      "Epoch 123/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5468 - accuracy: 0.7328 - val_loss: 0.5523 - val_accuracy: 0.7385\n",
      "Epoch 124/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5467 - accuracy: 0.7330 - val_loss: 0.5521 - val_accuracy: 0.7396\n",
      "Epoch 125/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5471 - accuracy: 0.7332 - val_loss: 0.5531 - val_accuracy: 0.7385\n",
      "Epoch 126/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5466 - accuracy: 0.7332 - val_loss: 0.5550 - val_accuracy: 0.7391\n",
      "Epoch 127/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5465 - accuracy: 0.7320 - val_loss: 0.5540 - val_accuracy: 0.7375\n",
      "Epoch 128/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5466 - accuracy: 0.7316 - val_loss: 0.5533 - val_accuracy: 0.7388\n",
      "Epoch 129/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5466 - accuracy: 0.7320 - val_loss: 0.5569 - val_accuracy: 0.7403\n",
      "Epoch 130/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5468 - accuracy: 0.7329 - val_loss: 0.5526 - val_accuracy: 0.7401\n",
      "Epoch 131/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5467 - accuracy: 0.7330 - val_loss: 0.5511 - val_accuracy: 0.7393\n",
      "Epoch 132/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5462 - accuracy: 0.7318 - val_loss: 0.5517 - val_accuracy: 0.7393\n",
      "Epoch 133/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5468 - accuracy: 0.7329 - val_loss: 0.5534 - val_accuracy: 0.7396\n",
      "Epoch 134/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5464 - accuracy: 0.7317 - val_loss: 0.5512 - val_accuracy: 0.7375\n",
      "Epoch 135/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5466 - accuracy: 0.7325 - val_loss: 0.5552 - val_accuracy: 0.7406\n",
      "Epoch 136/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5465 - accuracy: 0.7327 - val_loss: 0.5521 - val_accuracy: 0.7378\n",
      "Epoch 137/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5462 - accuracy: 0.7326 - val_loss: 0.5535 - val_accuracy: 0.7396\n",
      "Epoch 138/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5464 - accuracy: 0.7326 - val_loss: 0.5535 - val_accuracy: 0.7396\n",
      "Epoch 139/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5466 - accuracy: 0.7324 - val_loss: 0.5518 - val_accuracy: 0.7391\n",
      "Epoch 140/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5465 - accuracy: 0.7332 - val_loss: 0.5537 - val_accuracy: 0.7391\n",
      "Epoch 141/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5461 - accuracy: 0.7329 - val_loss: 0.5537 - val_accuracy: 0.7383\n",
      "Epoch 142/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5462 - accuracy: 0.7323 - val_loss: 0.5540 - val_accuracy: 0.7383\n",
      "Epoch 143/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5463 - accuracy: 0.7326 - val_loss: 0.5501 - val_accuracy: 0.7380\n",
      "Epoch 144/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5460 - accuracy: 0.7332 - val_loss: 0.5529 - val_accuracy: 0.7378\n",
      "Epoch 145/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5464 - accuracy: 0.7325 - val_loss: 0.5529 - val_accuracy: 0.7398\n",
      "Epoch 146/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5462 - accuracy: 0.7323 - val_loss: 0.5521 - val_accuracy: 0.7388\n",
      "Epoch 147/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5460 - accuracy: 0.7336 - val_loss: 0.5537 - val_accuracy: 0.7378\n",
      "Epoch 148/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5461 - accuracy: 0.7325 - val_loss: 0.5504 - val_accuracy: 0.7388\n",
      "Epoch 149/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5464 - accuracy: 0.7328 - val_loss: 0.5542 - val_accuracy: 0.7383\n",
      "Epoch 150/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5463 - accuracy: 0.7326 - val_loss: 0.5536 - val_accuracy: 0.7388\n",
      "Epoch 151/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5460 - accuracy: 0.7337 - val_loss: 0.5520 - val_accuracy: 0.7385\n",
      "Epoch 152/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5465 - accuracy: 0.7323 - val_loss: 0.5512 - val_accuracy: 0.7388\n",
      "Epoch 153/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5458 - accuracy: 0.7330 - val_loss: 0.5534 - val_accuracy: 0.7380\n",
      "Epoch 154/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5459 - accuracy: 0.7336 - val_loss: 0.5514 - val_accuracy: 0.7380\n",
      "Epoch 155/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5460 - accuracy: 0.7332 - val_loss: 0.5534 - val_accuracy: 0.7385\n",
      "Epoch 156/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5457 - accuracy: 0.7325 - val_loss: 0.5521 - val_accuracy: 0.7367\n",
      "Epoch 157/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7341 - val_loss: 0.5548 - val_accuracy: 0.7354\n",
      "Epoch 158/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5459 - accuracy: 0.7327 - val_loss: 0.5515 - val_accuracy: 0.7411\n",
      "Epoch 159/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5459 - accuracy: 0.7328 - val_loss: 0.5562 - val_accuracy: 0.7372\n",
      "Epoch 160/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5456 - accuracy: 0.7337 - val_loss: 0.5541 - val_accuracy: 0.7391\n",
      "Epoch 161/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5457 - accuracy: 0.7334 - val_loss: 0.5525 - val_accuracy: 0.7393\n",
      "Epoch 162/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5456 - accuracy: 0.7330 - val_loss: 0.5519 - val_accuracy: 0.7393\n",
      "Epoch 163/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5456 - accuracy: 0.7331 - val_loss: 0.5542 - val_accuracy: 0.7391\n",
      "Epoch 164/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5457 - accuracy: 0.7323 - val_loss: 0.5534 - val_accuracy: 0.7385\n",
      "Epoch 165/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5457 - accuracy: 0.7334 - val_loss: 0.5511 - val_accuracy: 0.7388\n",
      "Epoch 166/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5456 - accuracy: 0.7334 - val_loss: 0.5509 - val_accuracy: 0.7393\n",
      "Epoch 167/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5454 - accuracy: 0.7339 - val_loss: 0.5527 - val_accuracy: 0.7391\n",
      "Epoch 168/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5454 - accuracy: 0.7337 - val_loss: 0.5552 - val_accuracy: 0.7385\n",
      "Epoch 169/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5457 - accuracy: 0.7331 - val_loss: 0.5533 - val_accuracy: 0.7383\n",
      "Epoch 170/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5454 - accuracy: 0.7327 - val_loss: 0.5548 - val_accuracy: 0.7385\n",
      "Epoch 171/780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5460 - accuracy: 0.7330 - val_loss: 0.5553 - val_accuracy: 0.7398\n",
      "Epoch 172/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5454 - accuracy: 0.7335 - val_loss: 0.5520 - val_accuracy: 0.7380\n",
      "Epoch 173/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5456 - accuracy: 0.7333 - val_loss: 0.5557 - val_accuracy: 0.7341\n",
      "Epoch 174/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5453 - accuracy: 0.7333 - val_loss: 0.5579 - val_accuracy: 0.7328\n",
      "Epoch 175/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5456 - accuracy: 0.7332 - val_loss: 0.5552 - val_accuracy: 0.7398\n",
      "Epoch 176/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5453 - accuracy: 0.7335 - val_loss: 0.5559 - val_accuracy: 0.7362\n",
      "Epoch 177/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5454 - accuracy: 0.7334 - val_loss: 0.5522 - val_accuracy: 0.7391\n",
      "Epoch 178/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5456 - accuracy: 0.7335 - val_loss: 0.5567 - val_accuracy: 0.7365\n",
      "Epoch 179/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5456 - accuracy: 0.7334 - val_loss: 0.5546 - val_accuracy: 0.7396\n",
      "Epoch 180/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5454 - accuracy: 0.7334 - val_loss: 0.5554 - val_accuracy: 0.7388\n",
      "Epoch 181/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7329 - val_loss: 0.5528 - val_accuracy: 0.7401\n",
      "Epoch 182/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5457 - accuracy: 0.7328 - val_loss: 0.5524 - val_accuracy: 0.7380\n",
      "Epoch 183/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5451 - accuracy: 0.7345 - val_loss: 0.5544 - val_accuracy: 0.7388\n",
      "Epoch 184/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5451 - accuracy: 0.7341 - val_loss: 0.5527 - val_accuracy: 0.7383\n",
      "Epoch 185/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5453 - accuracy: 0.7335 - val_loss: 0.5538 - val_accuracy: 0.7401\n",
      "Epoch 186/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5455 - accuracy: 0.7337 - val_loss: 0.5546 - val_accuracy: 0.7391\n",
      "Epoch 187/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5451 - accuracy: 0.7346 - val_loss: 0.5544 - val_accuracy: 0.7375\n",
      "Epoch 188/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5454 - accuracy: 0.7329 - val_loss: 0.5516 - val_accuracy: 0.7391\n",
      "Epoch 189/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5452 - accuracy: 0.7334 - val_loss: 0.5554 - val_accuracy: 0.7344\n",
      "Epoch 190/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7331 - val_loss: 0.5565 - val_accuracy: 0.7378\n",
      "Epoch 191/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5452 - accuracy: 0.7341 - val_loss: 0.5531 - val_accuracy: 0.7391\n",
      "Epoch 192/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7331 - val_loss: 0.5556 - val_accuracy: 0.7370\n",
      "Epoch 193/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7335 - val_loss: 0.5587 - val_accuracy: 0.7388\n",
      "Epoch 194/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5452 - accuracy: 0.7338 - val_loss: 0.5546 - val_accuracy: 0.7383\n",
      "Epoch 195/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5453 - accuracy: 0.7328 - val_loss: 0.5529 - val_accuracy: 0.7385\n",
      "Epoch 196/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5449 - accuracy: 0.7330 - val_loss: 0.5533 - val_accuracy: 0.7391\n",
      "Epoch 197/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5449 - accuracy: 0.7332 - val_loss: 0.5543 - val_accuracy: 0.7378\n",
      "Epoch 198/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.7330 - val_loss: 0.5515 - val_accuracy: 0.7383\n",
      "Epoch 199/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5445 - accuracy: 0.7337 - val_loss: 0.5533 - val_accuracy: 0.7388\n",
      "Epoch 200/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5446 - accuracy: 0.7335 - val_loss: 0.5564 - val_accuracy: 0.7383\n",
      "Epoch 201/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5451 - accuracy: 0.7338 - val_loss: 0.5539 - val_accuracy: 0.7391\n",
      "Epoch 202/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5448 - accuracy: 0.7342 - val_loss: 0.5532 - val_accuracy: 0.7380\n",
      "Epoch 203/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5448 - accuracy: 0.7334 - val_loss: 0.5558 - val_accuracy: 0.7385\n",
      "Epoch 204/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5448 - accuracy: 0.7343 - val_loss: 0.5575 - val_accuracy: 0.7370\n",
      "Epoch 205/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7333 - val_loss: 0.5591 - val_accuracy: 0.7300\n",
      "Epoch 206/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7331 - val_loss: 0.5557 - val_accuracy: 0.7385\n",
      "Epoch 207/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5448 - accuracy: 0.7337 - val_loss: 0.5615 - val_accuracy: 0.7334\n",
      "Epoch 208/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5447 - accuracy: 0.7331 - val_loss: 0.5552 - val_accuracy: 0.7388\n",
      "Epoch 209/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5448 - accuracy: 0.7332 - val_loss: 0.5531 - val_accuracy: 0.7388\n",
      "Epoch 210/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5447 - accuracy: 0.7340 - val_loss: 0.5573 - val_accuracy: 0.7372\n",
      "Epoch 211/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7327 - val_loss: 0.5544 - val_accuracy: 0.7378\n",
      "Epoch 212/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5448 - accuracy: 0.7340 - val_loss: 0.5547 - val_accuracy: 0.7375\n",
      "Epoch 213/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7346 - val_loss: 0.5547 - val_accuracy: 0.7385\n",
      "Epoch 214/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5446 - accuracy: 0.7335 - val_loss: 0.5558 - val_accuracy: 0.7367\n",
      "Epoch 215/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5449 - accuracy: 0.7337 - val_loss: 0.5548 - val_accuracy: 0.7385\n",
      "Epoch 216/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5446 - accuracy: 0.7336 - val_loss: 0.5549 - val_accuracy: 0.7380\n",
      "Epoch 217/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5444 - accuracy: 0.7339 - val_loss: 0.5582 - val_accuracy: 0.7378\n",
      "Epoch 218/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5445 - accuracy: 0.7337 - val_loss: 0.5573 - val_accuracy: 0.7362\n",
      "Epoch 219/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7332 - val_loss: 0.5557 - val_accuracy: 0.7378\n",
      "Epoch 220/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7340 - val_loss: 0.5549 - val_accuracy: 0.7383\n",
      "Epoch 221/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7333 - val_loss: 0.5535 - val_accuracy: 0.7370\n",
      "Epoch 222/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7335 - val_loss: 0.5573 - val_accuracy: 0.7385\n",
      "Epoch 223/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7335 - val_loss: 0.5522 - val_accuracy: 0.7385\n",
      "Epoch 224/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7335 - val_loss: 0.5586 - val_accuracy: 0.7339\n",
      "Epoch 225/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5442 - accuracy: 0.7334 - val_loss: 0.5550 - val_accuracy: 0.7378\n",
      "Epoch 226/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7337 - val_loss: 0.5581 - val_accuracy: 0.7367\n",
      "Epoch 227/780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7330 - val_loss: 0.5550 - val_accuracy: 0.7370\n",
      "Epoch 228/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7339 - val_loss: 0.5548 - val_accuracy: 0.7385\n",
      "Epoch 229/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7337 - val_loss: 0.5577 - val_accuracy: 0.7393\n",
      "Epoch 230/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7334 - val_loss: 0.5566 - val_accuracy: 0.7375\n",
      "Epoch 231/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7333 - val_loss: 0.5594 - val_accuracy: 0.7357\n",
      "Epoch 232/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7340 - val_loss: 0.5566 - val_accuracy: 0.7354\n",
      "Epoch 233/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7331 - val_loss: 0.5536 - val_accuracy: 0.7367\n",
      "Epoch 234/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5442 - accuracy: 0.7332 - val_loss: 0.5572 - val_accuracy: 0.7370\n",
      "Epoch 235/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5441 - accuracy: 0.7330 - val_loss: 0.5543 - val_accuracy: 0.7378\n",
      "Epoch 236/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5437 - accuracy: 0.7340 - val_loss: 0.5562 - val_accuracy: 0.7383\n",
      "Epoch 237/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5442 - accuracy: 0.7344 - val_loss: 0.5574 - val_accuracy: 0.7370\n",
      "Epoch 238/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7327 - val_loss: 0.5550 - val_accuracy: 0.7380\n",
      "Epoch 239/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5440 - accuracy: 0.7344 - val_loss: 0.5586 - val_accuracy: 0.7344\n",
      "Epoch 240/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5442 - accuracy: 0.7331 - val_loss: 0.5571 - val_accuracy: 0.7359\n",
      "Epoch 241/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5442 - accuracy: 0.7338 - val_loss: 0.5549 - val_accuracy: 0.7365\n",
      "Epoch 242/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5442 - accuracy: 0.7343 - val_loss: 0.5557 - val_accuracy: 0.7385\n",
      "Epoch 243/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5440 - accuracy: 0.7342 - val_loss: 0.5585 - val_accuracy: 0.7385\n",
      "Epoch 244/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5439 - accuracy: 0.7338 - val_loss: 0.5573 - val_accuracy: 0.7380\n",
      "Epoch 245/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5439 - accuracy: 0.7343 - val_loss: 0.5570 - val_accuracy: 0.7365\n",
      "Epoch 246/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5443 - accuracy: 0.7335 - val_loss: 0.5585 - val_accuracy: 0.7380\n",
      "Epoch 247/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5441 - accuracy: 0.7350 - val_loss: 0.5569 - val_accuracy: 0.7383\n",
      "Epoch 248/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5440 - accuracy: 0.7337 - val_loss: 0.5551 - val_accuracy: 0.7375\n",
      "Epoch 249/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5442 - accuracy: 0.7342 - val_loss: 0.5564 - val_accuracy: 0.7365\n",
      "Epoch 250/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5437 - accuracy: 0.7340 - val_loss: 0.5560 - val_accuracy: 0.7365\n",
      "Epoch 251/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5438 - accuracy: 0.7346 - val_loss: 0.5567 - val_accuracy: 0.7380\n",
      "Epoch 252/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5439 - accuracy: 0.7346 - val_loss: 0.5557 - val_accuracy: 0.7385\n",
      "Epoch 253/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5442 - accuracy: 0.7335 - val_loss: 0.5585 - val_accuracy: 0.7352\n",
      "Epoch 254/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5439 - accuracy: 0.7340 - val_loss: 0.5574 - val_accuracy: 0.7367\n",
      "Epoch 255/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5441 - accuracy: 0.7344 - val_loss: 0.5549 - val_accuracy: 0.7370\n",
      "Epoch 256/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5436 - accuracy: 0.7338 - val_loss: 0.5564 - val_accuracy: 0.7370\n",
      "Epoch 257/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5441 - accuracy: 0.7338 - val_loss: 0.5590 - val_accuracy: 0.7367\n",
      "Epoch 258/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5438 - accuracy: 0.7344 - val_loss: 0.5607 - val_accuracy: 0.7365\n",
      "Epoch 259/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5435 - accuracy: 0.7350 - val_loss: 0.5577 - val_accuracy: 0.7375\n",
      "Epoch 260/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5440 - accuracy: 0.7340 - val_loss: 0.5559 - val_accuracy: 0.7367\n",
      "Epoch 261/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5438 - accuracy: 0.7340 - val_loss: 0.5567 - val_accuracy: 0.7359\n",
      "Epoch 262/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5435 - accuracy: 0.7340 - val_loss: 0.5582 - val_accuracy: 0.7378\n",
      "Epoch 263/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5439 - accuracy: 0.7347 - val_loss: 0.5571 - val_accuracy: 0.7365\n",
      "Epoch 264/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5436 - accuracy: 0.7336 - val_loss: 0.5562 - val_accuracy: 0.7372\n",
      "Epoch 265/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5436 - accuracy: 0.7335 - val_loss: 0.5579 - val_accuracy: 0.7383\n",
      "Epoch 266/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5438 - accuracy: 0.7347 - val_loss: 0.5549 - val_accuracy: 0.7357\n",
      "Epoch 267/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5434 - accuracy: 0.7347 - val_loss: 0.5565 - val_accuracy: 0.7372\n",
      "Epoch 268/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5437 - accuracy: 0.7333 - val_loss: 0.5567 - val_accuracy: 0.7378\n",
      "Epoch 269/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5437 - accuracy: 0.7343 - val_loss: 0.5588 - val_accuracy: 0.7372\n",
      "Epoch 270/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5436 - accuracy: 0.7340 - val_loss: 0.5590 - val_accuracy: 0.7383\n",
      "Epoch 271/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5439 - accuracy: 0.7340 - val_loss: 0.5585 - val_accuracy: 0.7334\n",
      "Epoch 272/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5437 - accuracy: 0.7338 - val_loss: 0.5589 - val_accuracy: 0.7362\n",
      "Epoch 273/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5437 - accuracy: 0.7344 - val_loss: 0.5565 - val_accuracy: 0.7375\n",
      "Epoch 274/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5438 - accuracy: 0.7341 - val_loss: 0.5565 - val_accuracy: 0.7357\n",
      "Epoch 275/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5438 - accuracy: 0.7338 - val_loss: 0.5527 - val_accuracy: 0.7370\n",
      "Epoch 276/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5438 - accuracy: 0.7343 - val_loss: 0.5560 - val_accuracy: 0.7367\n",
      "Epoch 277/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5438 - accuracy: 0.7347 - val_loss: 0.5601 - val_accuracy: 0.7359\n",
      "Epoch 278/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5438 - accuracy: 0.7334 - val_loss: 0.5585 - val_accuracy: 0.7365\n",
      "Epoch 279/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5438 - accuracy: 0.7338 - val_loss: 0.5572 - val_accuracy: 0.7359\n",
      "Epoch 280/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5433 - accuracy: 0.7340 - val_loss: 0.5575 - val_accuracy: 0.7375\n",
      "Epoch 281/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5439 - accuracy: 0.7333 - val_loss: 0.5613 - val_accuracy: 0.7334\n",
      "Epoch 282/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5434 - accuracy: 0.7336 - val_loss: 0.5565 - val_accuracy: 0.7354\n",
      "Epoch 283/780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5437 - accuracy: 0.7345 - val_loss: 0.5557 - val_accuracy: 0.7380\n",
      "Epoch 284/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5436 - accuracy: 0.7346 - val_loss: 0.5585 - val_accuracy: 0.7367\n",
      "Epoch 285/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5437 - accuracy: 0.7338 - val_loss: 0.5585 - val_accuracy: 0.7378\n",
      "Epoch 286/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5435 - accuracy: 0.7343 - val_loss: 0.5562 - val_accuracy: 0.7365\n",
      "Epoch 287/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5436 - accuracy: 0.7344 - val_loss: 0.5593 - val_accuracy: 0.7354\n",
      "Epoch 288/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5434 - accuracy: 0.7339 - val_loss: 0.5552 - val_accuracy: 0.7372\n",
      "Epoch 289/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5434 - accuracy: 0.7337 - val_loss: 0.5555 - val_accuracy: 0.7354\n",
      "Epoch 290/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5436 - accuracy: 0.7337 - val_loss: 0.5582 - val_accuracy: 0.7354\n",
      "Epoch 291/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5433 - accuracy: 0.7340 - val_loss: 0.5589 - val_accuracy: 0.7375\n",
      "Epoch 292/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5436 - accuracy: 0.7332 - val_loss: 0.5569 - val_accuracy: 0.7378\n",
      "Epoch 293/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5433 - accuracy: 0.7350 - val_loss: 0.5565 - val_accuracy: 0.7331\n",
      "Epoch 294/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5435 - accuracy: 0.7335 - val_loss: 0.5575 - val_accuracy: 0.7370\n",
      "Epoch 295/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5439 - accuracy: 0.7341 - val_loss: 0.5589 - val_accuracy: 0.7357\n",
      "Epoch 296/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5434 - accuracy: 0.7340 - val_loss: 0.5574 - val_accuracy: 0.7372\n",
      "Epoch 297/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5432 - accuracy: 0.7345 - val_loss: 0.5573 - val_accuracy: 0.7385\n",
      "Epoch 298/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5430 - accuracy: 0.7346 - val_loss: 0.5591 - val_accuracy: 0.7346\n",
      "Epoch 299/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5436 - accuracy: 0.7349 - val_loss: 0.5559 - val_accuracy: 0.7354\n",
      "Epoch 300/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5435 - accuracy: 0.7342 - val_loss: 0.5579 - val_accuracy: 0.7359\n",
      "Epoch 301/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5434 - accuracy: 0.7339 - val_loss: 0.5622 - val_accuracy: 0.7346\n",
      "Epoch 302/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5438 - accuracy: 0.7341 - val_loss: 0.5568 - val_accuracy: 0.7362\n",
      "Epoch 303/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5431 - accuracy: 0.7341 - val_loss: 0.5557 - val_accuracy: 0.7378\n",
      "Epoch 304/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5435 - accuracy: 0.7344 - val_loss: 0.5574 - val_accuracy: 0.7339\n",
      "Epoch 305/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5433 - accuracy: 0.7349 - val_loss: 0.5604 - val_accuracy: 0.7370\n",
      "Epoch 306/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5430 - accuracy: 0.7348 - val_loss: 0.5646 - val_accuracy: 0.7331\n",
      "Epoch 307/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5435 - accuracy: 0.7332 - val_loss: 0.5564 - val_accuracy: 0.7378\n",
      "Epoch 308/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5434 - accuracy: 0.7330 - val_loss: 0.5553 - val_accuracy: 0.7367\n",
      "Epoch 309/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5434 - accuracy: 0.7343 - val_loss: 0.5578 - val_accuracy: 0.7383\n",
      "Epoch 310/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5437 - accuracy: 0.7343 - val_loss: 0.5549 - val_accuracy: 0.7362\n",
      "Epoch 311/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5437 - accuracy: 0.7347 - val_loss: 0.5578 - val_accuracy: 0.7367\n",
      "Epoch 312/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5433 - accuracy: 0.7348 - val_loss: 0.5568 - val_accuracy: 0.7380\n",
      "Epoch 313/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5437 - accuracy: 0.7341 - val_loss: 0.5563 - val_accuracy: 0.7362\n",
      "Epoch 314/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5437 - accuracy: 0.7339 - val_loss: 0.5563 - val_accuracy: 0.7365\n",
      "Epoch 315/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5436 - accuracy: 0.7340 - val_loss: 0.5637 - val_accuracy: 0.7328\n",
      "Epoch 316/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5432 - accuracy: 0.7345 - val_loss: 0.5611 - val_accuracy: 0.7370\n",
      "Epoch 317/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5433 - accuracy: 0.7345 - val_loss: 0.5572 - val_accuracy: 0.7362\n",
      "Epoch 318/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7343 - val_loss: 0.5600 - val_accuracy: 0.7344\n",
      "Epoch 319/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5435 - accuracy: 0.7342 - val_loss: 0.5565 - val_accuracy: 0.7370\n",
      "Epoch 320/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5434 - accuracy: 0.7338 - val_loss: 0.5558 - val_accuracy: 0.7367\n",
      "Epoch 321/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7348 - val_loss: 0.5562 - val_accuracy: 0.7367\n",
      "Epoch 322/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5435 - accuracy: 0.7338 - val_loss: 0.5590 - val_accuracy: 0.7372\n",
      "Epoch 323/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5427 - accuracy: 0.7338 - val_loss: 0.5599 - val_accuracy: 0.7365\n",
      "Epoch 324/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5433 - accuracy: 0.7348 - val_loss: 0.5564 - val_accuracy: 0.7367\n",
      "Epoch 325/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7337 - val_loss: 0.5585 - val_accuracy: 0.7365\n",
      "Epoch 326/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5437 - accuracy: 0.7348 - val_loss: 0.5569 - val_accuracy: 0.7365\n",
      "Epoch 327/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5433 - accuracy: 0.7346 - val_loss: 0.5617 - val_accuracy: 0.7354\n",
      "Epoch 328/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5435 - accuracy: 0.7345 - val_loss: 0.5591 - val_accuracy: 0.7357\n",
      "Epoch 329/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5432 - accuracy: 0.7338 - val_loss: 0.5573 - val_accuracy: 0.7354\n",
      "Epoch 330/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5431 - accuracy: 0.7347 - val_loss: 0.5610 - val_accuracy: 0.7352\n",
      "Epoch 331/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5432 - accuracy: 0.7339 - val_loss: 0.5598 - val_accuracy: 0.7328\n",
      "Epoch 332/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5434 - accuracy: 0.7332 - val_loss: 0.5585 - val_accuracy: 0.7336\n",
      "Epoch 333/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5433 - accuracy: 0.7340 - val_loss: 0.5578 - val_accuracy: 0.7357\n",
      "Epoch 334/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7340 - val_loss: 0.5586 - val_accuracy: 0.7357\n",
      "Epoch 335/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5435 - accuracy: 0.7340 - val_loss: 0.5613 - val_accuracy: 0.7349\n",
      "Epoch 336/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5433 - accuracy: 0.7336 - val_loss: 0.5593 - val_accuracy: 0.7354\n",
      "Epoch 337/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5435 - accuracy: 0.7339 - val_loss: 0.5593 - val_accuracy: 0.7336\n",
      "Epoch 338/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5432 - accuracy: 0.7341 - val_loss: 0.5594 - val_accuracy: 0.7362\n",
      "Epoch 339/780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5437 - accuracy: 0.7338 - val_loss: 0.5595 - val_accuracy: 0.7357\n",
      "Epoch 340/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7346 - val_loss: 0.5574 - val_accuracy: 0.7365\n",
      "Epoch 341/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5432 - accuracy: 0.7339 - val_loss: 0.5577 - val_accuracy: 0.7365\n",
      "Epoch 342/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5430 - accuracy: 0.7351 - val_loss: 0.5667 - val_accuracy: 0.7310\n",
      "Epoch 343/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5434 - accuracy: 0.7334 - val_loss: 0.5623 - val_accuracy: 0.7357\n",
      "Epoch 344/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5430 - accuracy: 0.7337 - val_loss: 0.5626 - val_accuracy: 0.7352\n",
      "Epoch 345/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5430 - accuracy: 0.7346 - val_loss: 0.5621 - val_accuracy: 0.7336\n",
      "Epoch 346/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5433 - accuracy: 0.7343 - val_loss: 0.5560 - val_accuracy: 0.7357\n",
      "Epoch 347/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5431 - accuracy: 0.7348 - val_loss: 0.5631 - val_accuracy: 0.7295\n",
      "Epoch 348/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5435 - accuracy: 0.7341 - val_loss: 0.5601 - val_accuracy: 0.7357\n",
      "Epoch 349/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5432 - accuracy: 0.7351 - val_loss: 0.5602 - val_accuracy: 0.7362\n",
      "Epoch 350/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5431 - accuracy: 0.7339 - val_loss: 0.5609 - val_accuracy: 0.7365\n",
      "Epoch 351/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5431 - accuracy: 0.7340 - val_loss: 0.5607 - val_accuracy: 0.7357\n",
      "Epoch 352/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5429 - accuracy: 0.7342 - val_loss: 0.5602 - val_accuracy: 0.7354\n",
      "Epoch 353/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5432 - accuracy: 0.7340 - val_loss: 0.5653 - val_accuracy: 0.7339\n",
      "Epoch 354/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5428 - accuracy: 0.7337 - val_loss: 0.5608 - val_accuracy: 0.7354\n",
      "Epoch 355/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5430 - accuracy: 0.7342 - val_loss: 0.5607 - val_accuracy: 0.7341\n",
      "Epoch 356/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5434 - accuracy: 0.7349 - val_loss: 0.5602 - val_accuracy: 0.7362\n",
      "Epoch 357/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7337 - val_loss: 0.5617 - val_accuracy: 0.7359\n",
      "Epoch 358/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5430 - accuracy: 0.7341 - val_loss: 0.5579 - val_accuracy: 0.7362\n",
      "Epoch 359/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5428 - accuracy: 0.7351 - val_loss: 0.5598 - val_accuracy: 0.7346\n",
      "Epoch 360/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7338 - val_loss: 0.5591 - val_accuracy: 0.7367\n",
      "Epoch 361/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5430 - accuracy: 0.7340 - val_loss: 0.5593 - val_accuracy: 0.7375\n",
      "Epoch 362/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5433 - accuracy: 0.7337 - val_loss: 0.5558 - val_accuracy: 0.7362\n",
      "Epoch 363/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7355 - val_loss: 0.5616 - val_accuracy: 0.7367\n",
      "Epoch 364/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5434 - accuracy: 0.7341 - val_loss: 0.5600 - val_accuracy: 0.7362\n",
      "Epoch 365/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5432 - accuracy: 0.7350 - val_loss: 0.5576 - val_accuracy: 0.7349\n",
      "Epoch 366/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7343 - val_loss: 0.5578 - val_accuracy: 0.7357\n",
      "Epoch 367/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7350 - val_loss: 0.5588 - val_accuracy: 0.7362\n",
      "Epoch 368/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5429 - accuracy: 0.7356 - val_loss: 0.5632 - val_accuracy: 0.7331\n",
      "Epoch 369/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5432 - accuracy: 0.7337 - val_loss: 0.5582 - val_accuracy: 0.7357\n",
      "Epoch 370/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5427 - accuracy: 0.7340 - val_loss: 0.5596 - val_accuracy: 0.7362\n",
      "Epoch 371/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7336 - val_loss: 0.5592 - val_accuracy: 0.7336\n",
      "Epoch 372/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5429 - accuracy: 0.7341 - val_loss: 0.5616 - val_accuracy: 0.7359\n",
      "Epoch 373/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7335 - val_loss: 0.5596 - val_accuracy: 0.7354\n",
      "Epoch 374/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5430 - accuracy: 0.7343 - val_loss: 0.5601 - val_accuracy: 0.7328\n",
      "Epoch 375/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7340 - val_loss: 0.5573 - val_accuracy: 0.7367\n",
      "Epoch 376/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5430 - accuracy: 0.7344 - val_loss: 0.5601 - val_accuracy: 0.7378\n",
      "Epoch 377/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7340 - val_loss: 0.5620 - val_accuracy: 0.7367\n",
      "Epoch 378/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7350 - val_loss: 0.5597 - val_accuracy: 0.7352\n",
      "Epoch 379/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5427 - accuracy: 0.7343 - val_loss: 0.5589 - val_accuracy: 0.7349\n",
      "Epoch 380/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5426 - accuracy: 0.7345 - val_loss: 0.5562 - val_accuracy: 0.7344\n",
      "Epoch 381/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5433 - accuracy: 0.7349 - val_loss: 0.5594 - val_accuracy: 0.7349\n",
      "Epoch 382/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5430 - accuracy: 0.7332 - val_loss: 0.5623 - val_accuracy: 0.7308\n",
      "Epoch 383/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7340 - val_loss: 0.5574 - val_accuracy: 0.7352\n",
      "Epoch 384/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5427 - accuracy: 0.7344 - val_loss: 0.5585 - val_accuracy: 0.7354\n",
      "Epoch 385/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5427 - accuracy: 0.7347 - val_loss: 0.5604 - val_accuracy: 0.7321\n",
      "Epoch 386/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5428 - accuracy: 0.7345 - val_loss: 0.5590 - val_accuracy: 0.7359\n",
      "Epoch 387/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5432 - accuracy: 0.7340 - val_loss: 0.5616 - val_accuracy: 0.7357\n",
      "Epoch 388/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7352 - val_loss: 0.5639 - val_accuracy: 0.7359\n",
      "Epoch 389/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7347 - val_loss: 0.5624 - val_accuracy: 0.7362\n",
      "Epoch 390/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5430 - accuracy: 0.7351 - val_loss: 0.5570 - val_accuracy: 0.7346\n",
      "Epoch 391/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5427 - accuracy: 0.7348 - val_loss: 0.5608 - val_accuracy: 0.7331\n",
      "Epoch 392/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7343 - val_loss: 0.5610 - val_accuracy: 0.7341\n",
      "Epoch 393/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5427 - accuracy: 0.7348 - val_loss: 0.5568 - val_accuracy: 0.7354\n",
      "Epoch 394/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5430 - accuracy: 0.7348 - val_loss: 0.5573 - val_accuracy: 0.7359\n",
      "Epoch 395/780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5427 - accuracy: 0.7342 - val_loss: 0.5608 - val_accuracy: 0.7354\n",
      "Epoch 396/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5426 - accuracy: 0.7348 - val_loss: 0.5619 - val_accuracy: 0.7352\n",
      "Epoch 397/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5427 - accuracy: 0.7344 - val_loss: 0.5614 - val_accuracy: 0.7321\n",
      "Epoch 398/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7350 - val_loss: 0.5625 - val_accuracy: 0.7341\n",
      "Epoch 399/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5427 - accuracy: 0.7342 - val_loss: 0.5586 - val_accuracy: 0.7336\n",
      "Epoch 400/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5428 - accuracy: 0.7341 - val_loss: 0.5594 - val_accuracy: 0.7354\n",
      "Epoch 401/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5430 - accuracy: 0.7346 - val_loss: 0.5599 - val_accuracy: 0.7354\n",
      "Epoch 402/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7345 - val_loss: 0.5593 - val_accuracy: 0.7357\n",
      "Epoch 403/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5425 - accuracy: 0.7344 - val_loss: 0.5609 - val_accuracy: 0.7341\n",
      "Epoch 404/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5429 - accuracy: 0.7342 - val_loss: 0.5606 - val_accuracy: 0.7375\n",
      "Epoch 405/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5427 - accuracy: 0.7348 - val_loss: 0.5614 - val_accuracy: 0.7341\n",
      "Epoch 406/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5428 - accuracy: 0.7335 - val_loss: 0.5581 - val_accuracy: 0.7357\n",
      "Epoch 407/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5432 - accuracy: 0.7353 - val_loss: 0.5593 - val_accuracy: 0.7365\n",
      "Epoch 408/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5428 - accuracy: 0.7339 - val_loss: 0.5603 - val_accuracy: 0.7359\n",
      "Epoch 409/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7348 - val_loss: 0.5620 - val_accuracy: 0.7323\n",
      "Epoch 410/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5427 - accuracy: 0.7347 - val_loss: 0.5595 - val_accuracy: 0.7339\n",
      "Epoch 411/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7346 - val_loss: 0.5594 - val_accuracy: 0.7344\n",
      "Epoch 412/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5424 - accuracy: 0.7345 - val_loss: 0.5610 - val_accuracy: 0.7354\n",
      "Epoch 413/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7345 - val_loss: 0.5586 - val_accuracy: 0.7362\n",
      "Epoch 414/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5428 - accuracy: 0.7351 - val_loss: 0.5609 - val_accuracy: 0.7346\n",
      "Epoch 415/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5430 - accuracy: 0.7351 - val_loss: 0.5597 - val_accuracy: 0.7359\n",
      "Epoch 416/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5429 - accuracy: 0.7349 - val_loss: 0.5613 - val_accuracy: 0.7341\n",
      "Epoch 417/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5427 - accuracy: 0.7340 - val_loss: 0.5613 - val_accuracy: 0.7339\n",
      "Epoch 418/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5427 - accuracy: 0.7339 - val_loss: 0.5576 - val_accuracy: 0.7354\n",
      "Epoch 419/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5426 - accuracy: 0.7346 - val_loss: 0.5582 - val_accuracy: 0.7354\n",
      "Epoch 420/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5426 - accuracy: 0.7351 - val_loss: 0.5570 - val_accuracy: 0.7349\n",
      "Epoch 421/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5430 - accuracy: 0.7337 - val_loss: 0.5629 - val_accuracy: 0.7349\n",
      "Epoch 422/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5425 - accuracy: 0.7344 - val_loss: 0.5590 - val_accuracy: 0.7339\n",
      "Epoch 423/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.7342 - val_loss: 0.5601 - val_accuracy: 0.7359\n",
      "Epoch 424/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5429 - accuracy: 0.7340 - val_loss: 0.5591 - val_accuracy: 0.7362\n",
      "Epoch 425/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5428 - accuracy: 0.7340 - val_loss: 0.5608 - val_accuracy: 0.7359\n",
      "Epoch 426/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5426 - accuracy: 0.7339 - val_loss: 0.5591 - val_accuracy: 0.7357\n",
      "Epoch 427/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5427 - accuracy: 0.7335 - val_loss: 0.5595 - val_accuracy: 0.7344\n",
      "Epoch 428/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5425 - accuracy: 0.7350 - val_loss: 0.5629 - val_accuracy: 0.7365\n",
      "Epoch 429/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5426 - accuracy: 0.7345 - val_loss: 0.5594 - val_accuracy: 0.7365\n",
      "Epoch 430/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7353 - val_loss: 0.5607 - val_accuracy: 0.7362\n",
      "Epoch 431/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5430 - accuracy: 0.7354 - val_loss: 0.5586 - val_accuracy: 0.7357\n",
      "Epoch 432/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5425 - accuracy: 0.7345 - val_loss: 0.5590 - val_accuracy: 0.7346\n",
      "Epoch 433/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5428 - accuracy: 0.7340 - val_loss: 0.5624 - val_accuracy: 0.7359\n",
      "Epoch 434/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7346 - val_loss: 0.5554 - val_accuracy: 0.7367\n",
      "Epoch 435/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5427 - accuracy: 0.7355 - val_loss: 0.5620 - val_accuracy: 0.7341\n",
      "Epoch 436/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5424 - accuracy: 0.7346 - val_loss: 0.5610 - val_accuracy: 0.7321\n",
      "Epoch 437/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7349 - val_loss: 0.5573 - val_accuracy: 0.7365\n",
      "Epoch 438/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.7344 - val_loss: 0.5591 - val_accuracy: 0.7354\n",
      "Epoch 439/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5425 - accuracy: 0.7348 - val_loss: 0.5598 - val_accuracy: 0.7357\n",
      "Epoch 440/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5425 - accuracy: 0.7347 - val_loss: 0.5621 - val_accuracy: 0.7359\n",
      "Epoch 441/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5428 - accuracy: 0.7340 - val_loss: 0.5597 - val_accuracy: 0.7349\n",
      "Epoch 442/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.7354 - val_loss: 0.5608 - val_accuracy: 0.7362\n",
      "Epoch 443/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5427 - accuracy: 0.7346 - val_loss: 0.5611 - val_accuracy: 0.7357\n",
      "Epoch 444/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5427 - accuracy: 0.7346 - val_loss: 0.5576 - val_accuracy: 0.7357\n",
      "Epoch 445/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5425 - accuracy: 0.7350 - val_loss: 0.5592 - val_accuracy: 0.7354\n",
      "Epoch 446/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.7352 - val_loss: 0.5609 - val_accuracy: 0.7339\n",
      "Epoch 447/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5424 - accuracy: 0.7348 - val_loss: 0.5609 - val_accuracy: 0.7357\n",
      "Epoch 448/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5428 - accuracy: 0.7354 - val_loss: 0.5603 - val_accuracy: 0.7339\n",
      "Epoch 449/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5426 - accuracy: 0.7344 - val_loss: 0.5605 - val_accuracy: 0.7354\n",
      "Epoch 450/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7333 - val_loss: 0.5640 - val_accuracy: 0.7352\n",
      "Epoch 451/780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5425 - accuracy: 0.7347 - val_loss: 0.5629 - val_accuracy: 0.7365\n",
      "Epoch 452/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5428 - accuracy: 0.7344 - val_loss: 0.5616 - val_accuracy: 0.7336\n",
      "Epoch 453/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.7348 - val_loss: 0.5584 - val_accuracy: 0.7357\n",
      "Epoch 454/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.7354 - val_loss: 0.5574 - val_accuracy: 0.7354\n",
      "Epoch 455/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5424 - accuracy: 0.7350 - val_loss: 0.5577 - val_accuracy: 0.7349\n",
      "Epoch 456/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5424 - accuracy: 0.7343 - val_loss: 0.5580 - val_accuracy: 0.7359\n",
      "Epoch 457/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.7352 - val_loss: 0.5569 - val_accuracy: 0.7336\n",
      "Epoch 458/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.7348 - val_loss: 0.5586 - val_accuracy: 0.7349\n",
      "Epoch 459/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.7343 - val_loss: 0.5620 - val_accuracy: 0.7323\n",
      "Epoch 460/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7350 - val_loss: 0.5612 - val_accuracy: 0.7359\n",
      "Epoch 461/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7359 - val_loss: 0.5610 - val_accuracy: 0.7359\n",
      "Epoch 462/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5427 - accuracy: 0.7351 - val_loss: 0.5642 - val_accuracy: 0.7336\n",
      "Epoch 463/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5425 - accuracy: 0.7352 - val_loss: 0.5607 - val_accuracy: 0.7349\n",
      "Epoch 464/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7340 - val_loss: 0.5614 - val_accuracy: 0.7349\n",
      "Epoch 465/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7350 - val_loss: 0.5589 - val_accuracy: 0.7334\n",
      "Epoch 466/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7342 - val_loss: 0.5635 - val_accuracy: 0.7359\n",
      "Epoch 467/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.7346 - val_loss: 0.5592 - val_accuracy: 0.7359\n",
      "Epoch 468/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5424 - accuracy: 0.7345 - val_loss: 0.5606 - val_accuracy: 0.7354\n",
      "Epoch 469/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5424 - accuracy: 0.7341 - val_loss: 0.5591 - val_accuracy: 0.7357\n",
      "Epoch 470/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.7346 - val_loss: 0.5620 - val_accuracy: 0.7334\n",
      "Epoch 471/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5424 - accuracy: 0.7341 - val_loss: 0.5586 - val_accuracy: 0.7365\n",
      "Epoch 472/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5421 - accuracy: 0.7346 - val_loss: 0.5627 - val_accuracy: 0.7323\n",
      "Epoch 473/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7340 - val_loss: 0.5596 - val_accuracy: 0.7346\n",
      "Epoch 474/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7343 - val_loss: 0.5592 - val_accuracy: 0.7341\n",
      "Epoch 475/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7355 - val_loss: 0.5604 - val_accuracy: 0.7344\n",
      "Epoch 476/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7343 - val_loss: 0.5613 - val_accuracy: 0.7357\n",
      "Epoch 477/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5426 - accuracy: 0.7352 - val_loss: 0.5594 - val_accuracy: 0.7352\n",
      "Epoch 478/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7352 - val_loss: 0.5572 - val_accuracy: 0.7367\n",
      "Epoch 479/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7351 - val_loss: 0.5598 - val_accuracy: 0.7346\n",
      "Epoch 480/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7354 - val_loss: 0.5581 - val_accuracy: 0.7344\n",
      "Epoch 481/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7340 - val_loss: 0.5621 - val_accuracy: 0.7359\n",
      "Epoch 482/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7348 - val_loss: 0.5614 - val_accuracy: 0.7354\n",
      "Epoch 483/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7351 - val_loss: 0.5620 - val_accuracy: 0.7321\n",
      "Epoch 484/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7352 - val_loss: 0.5607 - val_accuracy: 0.7362\n",
      "Epoch 485/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5425 - accuracy: 0.7346 - val_loss: 0.5610 - val_accuracy: 0.7352\n",
      "Epoch 486/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.7354 - val_loss: 0.5587 - val_accuracy: 0.7354\n",
      "Epoch 487/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5424 - accuracy: 0.7356 - val_loss: 0.5603 - val_accuracy: 0.7362\n",
      "Epoch 488/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5421 - accuracy: 0.7341 - val_loss: 0.5615 - val_accuracy: 0.7339\n",
      "Epoch 489/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5424 - accuracy: 0.7347 - val_loss: 0.5618 - val_accuracy: 0.7367\n",
      "Epoch 490/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5421 - accuracy: 0.7344 - val_loss: 0.5642 - val_accuracy: 0.7295\n",
      "Epoch 491/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7349 - val_loss: 0.5644 - val_accuracy: 0.7328\n",
      "Epoch 492/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7359 - val_loss: 0.5619 - val_accuracy: 0.7354\n",
      "Epoch 493/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7344 - val_loss: 0.5639 - val_accuracy: 0.7323\n",
      "Epoch 494/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.7351 - val_loss: 0.5608 - val_accuracy: 0.7349\n",
      "Epoch 495/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5420 - accuracy: 0.7355 - val_loss: 0.5593 - val_accuracy: 0.7346\n",
      "Epoch 496/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7350 - val_loss: 0.5638 - val_accuracy: 0.7349\n",
      "Epoch 497/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5421 - accuracy: 0.7353 - val_loss: 0.5593 - val_accuracy: 0.7349\n",
      "Epoch 498/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.7357 - val_loss: 0.5639 - val_accuracy: 0.7336\n",
      "Epoch 499/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.7339 - val_loss: 0.5608 - val_accuracy: 0.7354\n",
      "Epoch 500/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.7351 - val_loss: 0.5624 - val_accuracy: 0.7352\n",
      "Epoch 501/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5424 - accuracy: 0.7346 - val_loss: 0.5604 - val_accuracy: 0.7357\n",
      "Epoch 502/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7349 - val_loss: 0.5588 - val_accuracy: 0.7359\n",
      "Epoch 503/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7351 - val_loss: 0.5609 - val_accuracy: 0.7346\n",
      "Epoch 504/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5421 - accuracy: 0.7349 - val_loss: 0.5611 - val_accuracy: 0.7352\n",
      "Epoch 505/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.7355 - val_loss: 0.5597 - val_accuracy: 0.7349\n",
      "Epoch 506/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7345 - val_loss: 0.5631 - val_accuracy: 0.7352\n",
      "Epoch 507/780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.7353 - val_loss: 0.5582 - val_accuracy: 0.7365\n",
      "Epoch 508/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7356 - val_loss: 0.5588 - val_accuracy: 0.7354\n",
      "Epoch 509/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7352 - val_loss: 0.5593 - val_accuracy: 0.7354\n",
      "Epoch 510/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5420 - accuracy: 0.7351 - val_loss: 0.5581 - val_accuracy: 0.7365\n",
      "Epoch 511/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5424 - accuracy: 0.7350 - val_loss: 0.5621 - val_accuracy: 0.7344\n",
      "Epoch 512/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5420 - accuracy: 0.7346 - val_loss: 0.5587 - val_accuracy: 0.7354\n",
      "Epoch 513/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.7356 - val_loss: 0.5591 - val_accuracy: 0.7372\n",
      "Epoch 514/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.7346 - val_loss: 0.5635 - val_accuracy: 0.7349\n",
      "Epoch 515/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7354 - val_loss: 0.5664 - val_accuracy: 0.7328\n",
      "Epoch 516/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7350 - val_loss: 0.5608 - val_accuracy: 0.7315\n",
      "Epoch 517/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7348 - val_loss: 0.5639 - val_accuracy: 0.7352\n",
      "Epoch 518/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7350 - val_loss: 0.5593 - val_accuracy: 0.7370\n",
      "Epoch 519/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.7351 - val_loss: 0.5593 - val_accuracy: 0.7339\n",
      "Epoch 520/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.7352 - val_loss: 0.5613 - val_accuracy: 0.7354\n",
      "Epoch 521/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7350 - val_loss: 0.5595 - val_accuracy: 0.7354\n",
      "Epoch 522/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7346 - val_loss: 0.5608 - val_accuracy: 0.7359\n",
      "Epoch 523/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7351 - val_loss: 0.5621 - val_accuracy: 0.7315\n",
      "Epoch 524/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5421 - accuracy: 0.7351 - val_loss: 0.5603 - val_accuracy: 0.7349\n",
      "Epoch 525/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7352 - val_loss: 0.5581 - val_accuracy: 0.7359\n",
      "Epoch 526/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.7358 - val_loss: 0.5602 - val_accuracy: 0.7359\n",
      "Epoch 527/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.7352 - val_loss: 0.5634 - val_accuracy: 0.7354\n",
      "Epoch 528/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.7342 - val_loss: 0.5584 - val_accuracy: 0.7354\n",
      "Epoch 529/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7350 - val_loss: 0.5606 - val_accuracy: 0.7362\n",
      "Epoch 530/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7353 - val_loss: 0.5607 - val_accuracy: 0.7357\n",
      "Epoch 531/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7346 - val_loss: 0.5611 - val_accuracy: 0.7331\n",
      "Epoch 532/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.7346 - val_loss: 0.5600 - val_accuracy: 0.7367\n",
      "Epoch 533/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7356 - val_loss: 0.5603 - val_accuracy: 0.7339\n",
      "Epoch 534/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7358 - val_loss: 0.5584 - val_accuracy: 0.7349\n",
      "Epoch 535/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7345 - val_loss: 0.5624 - val_accuracy: 0.7352\n",
      "Epoch 536/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7358 - val_loss: 0.5618 - val_accuracy: 0.7349\n",
      "Epoch 537/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7344 - val_loss: 0.5589 - val_accuracy: 0.7378\n",
      "Epoch 538/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7350 - val_loss: 0.5592 - val_accuracy: 0.7362\n",
      "Epoch 539/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7354 - val_loss: 0.5614 - val_accuracy: 0.7365\n",
      "Epoch 540/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.7347 - val_loss: 0.5637 - val_accuracy: 0.7334\n",
      "Epoch 541/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7365 - val_loss: 0.5598 - val_accuracy: 0.7365\n",
      "Epoch 542/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.7345 - val_loss: 0.5600 - val_accuracy: 0.7352\n",
      "Epoch 543/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7355 - val_loss: 0.5575 - val_accuracy: 0.7362\n",
      "Epoch 544/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7345 - val_loss: 0.5629 - val_accuracy: 0.7339\n",
      "Epoch 545/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7357 - val_loss: 0.5598 - val_accuracy: 0.7365\n",
      "Epoch 546/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7350 - val_loss: 0.5619 - val_accuracy: 0.7352\n",
      "Epoch 547/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7348 - val_loss: 0.5633 - val_accuracy: 0.7367\n",
      "Epoch 548/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5421 - accuracy: 0.7348 - val_loss: 0.5576 - val_accuracy: 0.7370\n",
      "Epoch 549/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7349 - val_loss: 0.5585 - val_accuracy: 0.7380\n",
      "Epoch 550/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.7342 - val_loss: 0.5600 - val_accuracy: 0.7365\n",
      "Epoch 551/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7350 - val_loss: 0.5578 - val_accuracy: 0.7370\n",
      "Epoch 552/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5420 - accuracy: 0.7345 - val_loss: 0.5626 - val_accuracy: 0.7365\n",
      "Epoch 553/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7353 - val_loss: 0.5586 - val_accuracy: 0.7380\n",
      "Epoch 554/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5421 - accuracy: 0.7352 - val_loss: 0.5609 - val_accuracy: 0.7354\n",
      "Epoch 555/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7356 - val_loss: 0.5591 - val_accuracy: 0.7365\n",
      "Epoch 556/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7354 - val_loss: 0.5603 - val_accuracy: 0.7375\n",
      "Epoch 557/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7353 - val_loss: 0.5580 - val_accuracy: 0.7365\n",
      "Epoch 558/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7346 - val_loss: 0.5637 - val_accuracy: 0.7372\n",
      "Epoch 559/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7357 - val_loss: 0.5602 - val_accuracy: 0.7359\n",
      "Epoch 560/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5421 - accuracy: 0.7360 - val_loss: 0.5615 - val_accuracy: 0.7365\n",
      "Epoch 561/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5420 - accuracy: 0.7343 - val_loss: 0.5619 - val_accuracy: 0.7365\n",
      "Epoch 562/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7348 - val_loss: 0.5593 - val_accuracy: 0.7380\n",
      "Epoch 563/780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7349 - val_loss: 0.5588 - val_accuracy: 0.7367\n",
      "Epoch 564/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7351 - val_loss: 0.5584 - val_accuracy: 0.7354\n",
      "Epoch 565/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7353 - val_loss: 0.5602 - val_accuracy: 0.7372\n",
      "Epoch 566/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7349 - val_loss: 0.5607 - val_accuracy: 0.7365\n",
      "Epoch 567/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5421 - accuracy: 0.7356 - val_loss: 0.5606 - val_accuracy: 0.7378\n",
      "Epoch 568/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7351 - val_loss: 0.5597 - val_accuracy: 0.7375\n",
      "Epoch 569/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.7341 - val_loss: 0.5606 - val_accuracy: 0.7362\n",
      "Epoch 570/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.7348 - val_loss: 0.5615 - val_accuracy: 0.7349\n",
      "Epoch 571/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7360 - val_loss: 0.5587 - val_accuracy: 0.7365\n",
      "Epoch 572/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7353 - val_loss: 0.5614 - val_accuracy: 0.7365\n",
      "Epoch 573/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7349 - val_loss: 0.5638 - val_accuracy: 0.7354\n",
      "Epoch 574/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5421 - accuracy: 0.7351 - val_loss: 0.5605 - val_accuracy: 0.7352\n",
      "Epoch 575/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7362 - val_loss: 0.5599 - val_accuracy: 0.7362\n",
      "Epoch 576/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7356 - val_loss: 0.5604 - val_accuracy: 0.7346\n",
      "Epoch 577/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7350 - val_loss: 0.5604 - val_accuracy: 0.7370\n",
      "Epoch 578/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7363 - val_loss: 0.5629 - val_accuracy: 0.7378\n",
      "Epoch 579/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7355 - val_loss: 0.5599 - val_accuracy: 0.7313\n",
      "Epoch 580/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7358 - val_loss: 0.5596 - val_accuracy: 0.7362\n",
      "Epoch 581/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7346 - val_loss: 0.5598 - val_accuracy: 0.7359\n",
      "Epoch 582/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7351 - val_loss: 0.5623 - val_accuracy: 0.7352\n",
      "Epoch 583/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7348 - val_loss: 0.5624 - val_accuracy: 0.7365\n",
      "Epoch 584/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7356 - val_loss: 0.5587 - val_accuracy: 0.7365\n",
      "Epoch 585/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5420 - accuracy: 0.7354 - val_loss: 0.5646 - val_accuracy: 0.7339\n",
      "Epoch 586/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7347 - val_loss: 0.5585 - val_accuracy: 0.7354\n",
      "Epoch 587/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7350 - val_loss: 0.5616 - val_accuracy: 0.7367\n",
      "Epoch 588/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7352 - val_loss: 0.5613 - val_accuracy: 0.7359\n",
      "Epoch 589/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7352 - val_loss: 0.5596 - val_accuracy: 0.7378\n",
      "Epoch 590/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5415 - accuracy: 0.7354 - val_loss: 0.5617 - val_accuracy: 0.7357\n",
      "Epoch 591/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5421 - accuracy: 0.7349 - val_loss: 0.5622 - val_accuracy: 0.7346\n",
      "Epoch 592/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5416 - accuracy: 0.7349 - val_loss: 0.5609 - val_accuracy: 0.7349\n",
      "Epoch 593/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7350 - val_loss: 0.5620 - val_accuracy: 0.7378\n",
      "Epoch 594/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7353 - val_loss: 0.5610 - val_accuracy: 0.7367\n",
      "Epoch 595/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5420 - accuracy: 0.7354 - val_loss: 0.5594 - val_accuracy: 0.7354\n",
      "Epoch 596/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7350 - val_loss: 0.5589 - val_accuracy: 0.7365\n",
      "Epoch 597/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7351 - val_loss: 0.5601 - val_accuracy: 0.7378\n",
      "Epoch 598/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7347 - val_loss: 0.5627 - val_accuracy: 0.7352\n",
      "Epoch 599/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.7356 - val_loss: 0.5637 - val_accuracy: 0.7365\n",
      "Epoch 600/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7351 - val_loss: 0.5597 - val_accuracy: 0.7370\n",
      "Epoch 601/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7353 - val_loss: 0.5582 - val_accuracy: 0.7372\n",
      "Epoch 602/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7345 - val_loss: 0.5577 - val_accuracy: 0.7362\n",
      "Epoch 603/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7356 - val_loss: 0.5615 - val_accuracy: 0.7352\n",
      "Epoch 604/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7356 - val_loss: 0.5610 - val_accuracy: 0.7365\n",
      "Epoch 605/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7353 - val_loss: 0.5617 - val_accuracy: 0.7367\n",
      "Epoch 606/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5415 - accuracy: 0.7355 - val_loss: 0.5601 - val_accuracy: 0.7357\n",
      "Epoch 607/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5425 - accuracy: 0.7355 - val_loss: 0.5614 - val_accuracy: 0.7326\n",
      "Epoch 608/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5420 - accuracy: 0.7343 - val_loss: 0.5572 - val_accuracy: 0.7375\n",
      "Epoch 609/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5420 - accuracy: 0.7351 - val_loss: 0.5591 - val_accuracy: 0.7344\n",
      "Epoch 610/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7349 - val_loss: 0.5630 - val_accuracy: 0.7372\n",
      "Epoch 611/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7358 - val_loss: 0.5613 - val_accuracy: 0.7352\n",
      "Epoch 612/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5416 - accuracy: 0.7351 - val_loss: 0.5621 - val_accuracy: 0.7380\n",
      "Epoch 613/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7350 - val_loss: 0.5619 - val_accuracy: 0.7365\n",
      "Epoch 614/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7359 - val_loss: 0.5619 - val_accuracy: 0.7362\n",
      "Epoch 615/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7347 - val_loss: 0.5589 - val_accuracy: 0.7359\n",
      "Epoch 616/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5416 - accuracy: 0.7347 - val_loss: 0.5613 - val_accuracy: 0.7357\n",
      "Epoch 617/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7357 - val_loss: 0.5619 - val_accuracy: 0.7359\n",
      "Epoch 618/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7358 - val_loss: 0.5603 - val_accuracy: 0.7391\n",
      "Epoch 619/780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7351 - val_loss: 0.5616 - val_accuracy: 0.7370\n",
      "Epoch 620/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7355 - val_loss: 0.5647 - val_accuracy: 0.7365\n",
      "Epoch 621/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5416 - accuracy: 0.7351 - val_loss: 0.5623 - val_accuracy: 0.7354\n",
      "Epoch 622/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7364 - val_loss: 0.5644 - val_accuracy: 0.7362\n",
      "Epoch 623/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7355 - val_loss: 0.5604 - val_accuracy: 0.7370\n",
      "Epoch 624/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7353 - val_loss: 0.5619 - val_accuracy: 0.7365\n",
      "Epoch 625/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5416 - accuracy: 0.7356 - val_loss: 0.5619 - val_accuracy: 0.7372\n",
      "Epoch 626/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5415 - accuracy: 0.7349 - val_loss: 0.5599 - val_accuracy: 0.7362\n",
      "Epoch 627/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7346 - val_loss: 0.5641 - val_accuracy: 0.7357\n",
      "Epoch 628/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7356 - val_loss: 0.5590 - val_accuracy: 0.7375\n",
      "Epoch 629/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7357 - val_loss: 0.5597 - val_accuracy: 0.7346\n",
      "Epoch 630/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7356 - val_loss: 0.5601 - val_accuracy: 0.7367\n",
      "Epoch 631/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7349 - val_loss: 0.5641 - val_accuracy: 0.7357\n",
      "Epoch 632/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5415 - accuracy: 0.7353 - val_loss: 0.5581 - val_accuracy: 0.7380\n",
      "Epoch 633/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7355 - val_loss: 0.5611 - val_accuracy: 0.7372\n",
      "Epoch 634/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5415 - accuracy: 0.7353 - val_loss: 0.5578 - val_accuracy: 0.7370\n",
      "Epoch 635/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7357 - val_loss: 0.5583 - val_accuracy: 0.7385\n",
      "Epoch 636/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7352 - val_loss: 0.5624 - val_accuracy: 0.7344\n",
      "Epoch 637/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7360 - val_loss: 0.5607 - val_accuracy: 0.7357\n",
      "Epoch 638/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5415 - accuracy: 0.7351 - val_loss: 0.5638 - val_accuracy: 0.7359\n",
      "Epoch 639/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7353 - val_loss: 0.5652 - val_accuracy: 0.7365\n",
      "Epoch 640/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7355 - val_loss: 0.5588 - val_accuracy: 0.7380\n",
      "Epoch 641/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7360 - val_loss: 0.5586 - val_accuracy: 0.7372\n",
      "Epoch 642/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5416 - accuracy: 0.7351 - val_loss: 0.5591 - val_accuracy: 0.7352\n",
      "Epoch 643/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7355 - val_loss: 0.5632 - val_accuracy: 0.7367\n",
      "Epoch 644/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7357 - val_loss: 0.5607 - val_accuracy: 0.7359\n",
      "Epoch 645/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7365 - val_loss: 0.5618 - val_accuracy: 0.7388\n",
      "Epoch 646/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7350 - val_loss: 0.5654 - val_accuracy: 0.7334\n",
      "Epoch 647/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7354 - val_loss: 0.5620 - val_accuracy: 0.7362\n",
      "Epoch 648/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7355 - val_loss: 0.5614 - val_accuracy: 0.7362\n",
      "Epoch 649/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7362 - val_loss: 0.5608 - val_accuracy: 0.7375\n",
      "Epoch 650/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7349 - val_loss: 0.5593 - val_accuracy: 0.7372\n",
      "Epoch 651/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7364 - val_loss: 0.5568 - val_accuracy: 0.7375\n",
      "Epoch 652/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5413 - accuracy: 0.7356 - val_loss: 0.5624 - val_accuracy: 0.7362\n",
      "Epoch 653/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7356 - val_loss: 0.5608 - val_accuracy: 0.7349\n",
      "Epoch 654/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7358 - val_loss: 0.5628 - val_accuracy: 0.7375\n",
      "Epoch 655/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5412 - accuracy: 0.7360 - val_loss: 0.5612 - val_accuracy: 0.7370\n",
      "Epoch 656/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5416 - accuracy: 0.7348 - val_loss: 0.5648 - val_accuracy: 0.7339\n",
      "Epoch 657/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7354 - val_loss: 0.5622 - val_accuracy: 0.7378\n",
      "Epoch 658/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5413 - accuracy: 0.7354 - val_loss: 0.5661 - val_accuracy: 0.7326\n",
      "Epoch 659/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7352 - val_loss: 0.5622 - val_accuracy: 0.7365\n",
      "Epoch 660/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5414 - accuracy: 0.7361 - val_loss: 0.5666 - val_accuracy: 0.7315\n",
      "Epoch 661/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5415 - accuracy: 0.7351 - val_loss: 0.5594 - val_accuracy: 0.7372\n",
      "Epoch 662/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5413 - accuracy: 0.7359 - val_loss: 0.5621 - val_accuracy: 0.7354\n",
      "Epoch 663/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7355 - val_loss: 0.5625 - val_accuracy: 0.7367\n",
      "Epoch 664/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5414 - accuracy: 0.7365 - val_loss: 0.5650 - val_accuracy: 0.7346\n",
      "Epoch 665/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7351 - val_loss: 0.5634 - val_accuracy: 0.7365\n",
      "Epoch 666/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5413 - accuracy: 0.7357 - val_loss: 0.5631 - val_accuracy: 0.7357\n",
      "Epoch 667/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5414 - accuracy: 0.7352 - val_loss: 0.5631 - val_accuracy: 0.7359\n",
      "Epoch 668/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5414 - accuracy: 0.7350 - val_loss: 0.5660 - val_accuracy: 0.7331\n",
      "Epoch 669/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7359 - val_loss: 0.5606 - val_accuracy: 0.7362\n",
      "Epoch 670/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5415 - accuracy: 0.7348 - val_loss: 0.5635 - val_accuracy: 0.7357\n",
      "Epoch 671/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7347 - val_loss: 0.5622 - val_accuracy: 0.7367\n",
      "Epoch 672/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7347 - val_loss: 0.5651 - val_accuracy: 0.7367\n",
      "Epoch 673/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5416 - accuracy: 0.7349 - val_loss: 0.5626 - val_accuracy: 0.7362\n",
      "Epoch 674/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7355 - val_loss: 0.5617 - val_accuracy: 0.7367\n",
      "Epoch 675/780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5413 - accuracy: 0.7353 - val_loss: 0.5624 - val_accuracy: 0.7365\n",
      "Epoch 676/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5416 - accuracy: 0.7352 - val_loss: 0.5650 - val_accuracy: 0.7349\n",
      "Epoch 677/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5412 - accuracy: 0.7359 - val_loss: 0.5625 - val_accuracy: 0.7391\n",
      "Epoch 678/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5415 - accuracy: 0.7354 - val_loss: 0.5626 - val_accuracy: 0.7357\n",
      "Epoch 679/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7351 - val_loss: 0.5671 - val_accuracy: 0.7331\n",
      "Epoch 680/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7359 - val_loss: 0.5631 - val_accuracy: 0.7370\n",
      "Epoch 681/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7352 - val_loss: 0.5645 - val_accuracy: 0.7326\n",
      "Epoch 682/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7340 - val_loss: 0.5686 - val_accuracy: 0.7357\n",
      "Epoch 683/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5411 - accuracy: 0.7357 - val_loss: 0.5636 - val_accuracy: 0.7367\n",
      "Epoch 684/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5411 - accuracy: 0.7346 - val_loss: 0.5639 - val_accuracy: 0.7372\n",
      "Epoch 685/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7356 - val_loss: 0.5607 - val_accuracy: 0.7367\n",
      "Epoch 686/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5412 - accuracy: 0.7352 - val_loss: 0.5676 - val_accuracy: 0.7331\n",
      "Epoch 687/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5414 - accuracy: 0.7358 - val_loss: 0.5633 - val_accuracy: 0.7383\n",
      "Epoch 688/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5415 - accuracy: 0.7348 - val_loss: 0.5628 - val_accuracy: 0.7372\n",
      "Epoch 689/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7352 - val_loss: 0.5679 - val_accuracy: 0.7359\n",
      "Epoch 690/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5415 - accuracy: 0.7353 - val_loss: 0.5688 - val_accuracy: 0.7362\n",
      "Epoch 691/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5415 - accuracy: 0.7356 - val_loss: 0.5606 - val_accuracy: 0.7370\n",
      "Epoch 692/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7356 - val_loss: 0.5597 - val_accuracy: 0.7367\n",
      "Epoch 693/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7355 - val_loss: 0.5639 - val_accuracy: 0.7352\n",
      "Epoch 694/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7359 - val_loss: 0.5647 - val_accuracy: 0.7357\n",
      "Epoch 695/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5416 - accuracy: 0.7354 - val_loss: 0.5629 - val_accuracy: 0.7370\n",
      "Epoch 696/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5416 - accuracy: 0.7347 - val_loss: 0.5623 - val_accuracy: 0.7365\n",
      "Epoch 697/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5415 - accuracy: 0.7356 - val_loss: 0.5640 - val_accuracy: 0.7365\n",
      "Epoch 698/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7346 - val_loss: 0.5635 - val_accuracy: 0.7372\n",
      "Epoch 699/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5415 - accuracy: 0.7355 - val_loss: 0.5652 - val_accuracy: 0.7336\n",
      "Epoch 700/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7357 - val_loss: 0.5599 - val_accuracy: 0.7385\n",
      "Epoch 701/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7353 - val_loss: 0.5634 - val_accuracy: 0.7367\n",
      "Epoch 702/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5415 - accuracy: 0.7358 - val_loss: 0.5612 - val_accuracy: 0.7367\n",
      "Epoch 703/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5416 - accuracy: 0.7365 - val_loss: 0.5600 - val_accuracy: 0.7359\n",
      "Epoch 704/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5414 - accuracy: 0.7349 - val_loss: 0.5710 - val_accuracy: 0.7334\n",
      "Epoch 705/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5414 - accuracy: 0.7352 - val_loss: 0.5656 - val_accuracy: 0.7365\n",
      "Epoch 706/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5411 - accuracy: 0.7361 - val_loss: 0.5657 - val_accuracy: 0.7359\n",
      "Epoch 707/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7360 - val_loss: 0.5606 - val_accuracy: 0.7336\n",
      "Epoch 708/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5427 - accuracy: 0.7361 - val_loss: 0.5605 - val_accuracy: 0.7359\n",
      "Epoch 709/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.7356 - val_loss: 0.5629 - val_accuracy: 0.7378\n",
      "Epoch 710/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5411 - accuracy: 0.7347 - val_loss: 0.5644 - val_accuracy: 0.7339\n",
      "Epoch 711/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7350 - val_loss: 0.5623 - val_accuracy: 0.7370\n",
      "Epoch 712/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5413 - accuracy: 0.7357 - val_loss: 0.5630 - val_accuracy: 0.7367\n",
      "Epoch 713/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5414 - accuracy: 0.7357 - val_loss: 0.5637 - val_accuracy: 0.7370\n",
      "Epoch 714/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5413 - accuracy: 0.7356 - val_loss: 0.5671 - val_accuracy: 0.7352\n",
      "Epoch 715/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5415 - accuracy: 0.7360 - val_loss: 0.5620 - val_accuracy: 0.7372\n",
      "Epoch 716/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5415 - accuracy: 0.7353 - val_loss: 0.5655 - val_accuracy: 0.7375\n",
      "Epoch 717/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7354 - val_loss: 0.5651 - val_accuracy: 0.7367\n",
      "Epoch 718/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7359 - val_loss: 0.5646 - val_accuracy: 0.7370\n",
      "Epoch 719/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7362 - val_loss: 0.5645 - val_accuracy: 0.7378\n",
      "Epoch 720/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7362 - val_loss: 0.5659 - val_accuracy: 0.7359\n",
      "Epoch 721/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7357 - val_loss: 0.5669 - val_accuracy: 0.7357\n",
      "Epoch 722/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7357 - val_loss: 0.5664 - val_accuracy: 0.7362\n",
      "Epoch 723/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7357 - val_loss: 0.5626 - val_accuracy: 0.7326\n",
      "Epoch 724/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7358 - val_loss: 0.5618 - val_accuracy: 0.7354\n",
      "Epoch 725/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5414 - accuracy: 0.7357 - val_loss: 0.5631 - val_accuracy: 0.7365\n",
      "Epoch 726/780\n",
      "684/684 [==============================] - 1s 1ms/step - loss: 0.5414 - accuracy: 0.7347 - val_loss: 0.5623 - val_accuracy: 0.7365\n",
      "Epoch 727/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5415 - accuracy: 0.7356 - val_loss: 0.5633 - val_accuracy: 0.7370\n",
      "Epoch 728/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5411 - accuracy: 0.7351 - val_loss: 0.5639 - val_accuracy: 0.7372\n",
      "Epoch 729/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7351 - val_loss: 0.5620 - val_accuracy: 0.7352\n",
      "Epoch 730/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5411 - accuracy: 0.7363 - val_loss: 0.5635 - val_accuracy: 0.7359\n",
      "Epoch 731/780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5415 - accuracy: 0.7351 - val_loss: 0.5646 - val_accuracy: 0.7357\n",
      "Epoch 732/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7353 - val_loss: 0.5635 - val_accuracy: 0.7352\n",
      "Epoch 733/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7362 - val_loss: 0.5689 - val_accuracy: 0.7349\n",
      "Epoch 734/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7353 - val_loss: 0.5635 - val_accuracy: 0.7375\n",
      "Epoch 735/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7351 - val_loss: 0.5673 - val_accuracy: 0.7375\n",
      "Epoch 736/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5411 - accuracy: 0.7362 - val_loss: 0.5639 - val_accuracy: 0.7344\n",
      "Epoch 737/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7357 - val_loss: 0.5651 - val_accuracy: 0.7349\n",
      "Epoch 738/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5411 - accuracy: 0.7360 - val_loss: 0.5640 - val_accuracy: 0.7349\n",
      "Epoch 739/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7358 - val_loss: 0.5662 - val_accuracy: 0.7380\n",
      "Epoch 740/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7370 - val_loss: 0.5640 - val_accuracy: 0.7372\n",
      "Epoch 741/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7351 - val_loss: 0.5668 - val_accuracy: 0.7362\n",
      "Epoch 742/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7354 - val_loss: 0.5651 - val_accuracy: 0.7359\n",
      "Epoch 743/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7357 - val_loss: 0.5613 - val_accuracy: 0.7359\n",
      "Epoch 744/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5415 - accuracy: 0.7354 - val_loss: 0.5658 - val_accuracy: 0.7375\n",
      "Epoch 745/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7355 - val_loss: 0.5634 - val_accuracy: 0.7357\n",
      "Epoch 746/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5411 - accuracy: 0.7355 - val_loss: 0.5667 - val_accuracy: 0.7365\n",
      "Epoch 747/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7361 - val_loss: 0.5614 - val_accuracy: 0.7331\n",
      "Epoch 748/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7357 - val_loss: 0.5634 - val_accuracy: 0.7362\n",
      "Epoch 749/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7358 - val_loss: 0.5631 - val_accuracy: 0.7370\n",
      "Epoch 750/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7343 - val_loss: 0.5647 - val_accuracy: 0.7328\n",
      "Epoch 751/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7361 - val_loss: 0.5637 - val_accuracy: 0.7354\n",
      "Epoch 752/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7359 - val_loss: 0.5624 - val_accuracy: 0.7349\n",
      "Epoch 753/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5415 - accuracy: 0.7360 - val_loss: 0.5650 - val_accuracy: 0.7354\n",
      "Epoch 754/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7353 - val_loss: 0.5637 - val_accuracy: 0.7359\n",
      "Epoch 755/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7359 - val_loss: 0.5633 - val_accuracy: 0.7359\n",
      "Epoch 756/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7348 - val_loss: 0.5660 - val_accuracy: 0.7362\n",
      "Epoch 757/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5411 - accuracy: 0.7359 - val_loss: 0.5693 - val_accuracy: 0.7339\n",
      "Epoch 758/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7364 - val_loss: 0.5669 - val_accuracy: 0.7359\n",
      "Epoch 759/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7351 - val_loss: 0.5657 - val_accuracy: 0.7367\n",
      "Epoch 760/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7357 - val_loss: 0.5666 - val_accuracy: 0.7362\n",
      "Epoch 761/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7357 - val_loss: 0.5611 - val_accuracy: 0.7359\n",
      "Epoch 762/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7362 - val_loss: 0.5675 - val_accuracy: 0.7334\n",
      "Epoch 763/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5411 - accuracy: 0.7358 - val_loss: 0.5647 - val_accuracy: 0.7378\n",
      "Epoch 764/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7357 - val_loss: 0.5669 - val_accuracy: 0.7336\n",
      "Epoch 765/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5415 - accuracy: 0.7356 - val_loss: 0.5626 - val_accuracy: 0.7359\n",
      "Epoch 766/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7345 - val_loss: 0.5642 - val_accuracy: 0.7352\n",
      "Epoch 767/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7354 - val_loss: 0.5668 - val_accuracy: 0.7367\n",
      "Epoch 768/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7351 - val_loss: 0.5643 - val_accuracy: 0.7362\n",
      "Epoch 769/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7360 - val_loss: 0.5604 - val_accuracy: 0.7378\n",
      "Epoch 770/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7344 - val_loss: 0.5644 - val_accuracy: 0.7354\n",
      "Epoch 771/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5411 - accuracy: 0.7357 - val_loss: 0.5638 - val_accuracy: 0.7378\n",
      "Epoch 772/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7360 - val_loss: 0.5645 - val_accuracy: 0.7359\n",
      "Epoch 773/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7358 - val_loss: 0.5630 - val_accuracy: 0.7362\n",
      "Epoch 774/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7363 - val_loss: 0.5641 - val_accuracy: 0.7367\n",
      "Epoch 775/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7361 - val_loss: 0.5632 - val_accuracy: 0.7375\n",
      "Epoch 776/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5415 - accuracy: 0.7357 - val_loss: 0.5633 - val_accuracy: 0.7370\n",
      "Epoch 777/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7352 - val_loss: 0.5712 - val_accuracy: 0.7334\n",
      "Epoch 778/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7358 - val_loss: 0.5637 - val_accuracy: 0.7346\n",
      "Epoch 779/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7348 - val_loss: 0.5648 - val_accuracy: 0.7372\n",
      "Epoch 780/780\n",
      "684/684 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7348 - val_loss: 0.5663 - val_accuracy: 0.7367\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,validation_split=0.15, epochs=780)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5516 - accuracy: 0.7378 - 288ms/epoch - 1ms/step\n",
      "Loss: 0.5515739321708679, Accuracy: 0.7378425598144531\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Export our model to HDF5 file\n",
    "# .h5 files are considered legacy and the library suggested to save it as .keras, saved both formats.\n",
    "nn.save(\"./modelHDF5_2.h5\")\n",
    "nn.save(\"./modelKERAS_2.keras\")\n",
    "plot_df = pd.DataFrame(fit_model.history, index = range(1, len(fit_model.history['loss'])+1))\n",
    "plot_df.plot(y = 'accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
